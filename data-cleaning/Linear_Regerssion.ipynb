{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from adaptivenetworks.nnetwork import nnetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>powder</th>\n",
       "      <th>salt</th>\n",
       "      <th>oil</th>\n",
       "      <th>edible</th>\n",
       "      <th>vegetable</th>\n",
       "      <th>wheat</th>\n",
       "      <th>flour</th>\n",
       "      <th>sugar</th>\n",
       "      <th>chilli</th>\n",
       "      <th>red</th>\n",
       "      <th>...</th>\n",
       "      <th>tocopheryl</th>\n",
       "      <th>triethanolamine</th>\n",
       "      <th>cl</th>\n",
       "      <th>titanium</th>\n",
       "      <th>dioxide</th>\n",
       "      <th>root</th>\n",
       "      <th>stearate</th>\n",
       "      <th>orange</th>\n",
       "      <th>honey</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   powder  salt  oil  edible  vegetable  wheat  flour  sugar  chilli  red  \\\n",
       "0       1     1    1       1          1      0      1      0       1    1   \n",
       "1       0     0    0       0          0      0      0      0       0    0   \n",
       "2       0     0    0       0          0      0      0      0       0    0   \n",
       "3       0     0    1       0          0      0      0      0       0    0   \n",
       "4       0     0    0       0          0      0      0      0       0    0   \n",
       "\n",
       "   ...  tocopheryl  triethanolamine  cl  titanium  dioxide  root  stearate  \\\n",
       "0  ...           0                0   0         0        0     0         0   \n",
       "1  ...           0                0   0         0        0     0         0   \n",
       "2  ...           0                0   0         0        0     0         0   \n",
       "3  ...           0                0   0         0        0     0         0   \n",
       "4  ...           0                0   0         0        0     0         0   \n",
       "\n",
       "   orange  honey  TYPE  \n",
       "0       0      0     0  \n",
       "1       0      0     1  \n",
       "2       0      0     1  \n",
       "3       0      0     1  \n",
       "4       0      0     1  \n",
       "\n",
       "[5 rows x 114 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"ml_prj_dataset.csv\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>powder</th>\n",
       "      <th>salt</th>\n",
       "      <th>oil</th>\n",
       "      <th>edible</th>\n",
       "      <th>vegetable</th>\n",
       "      <th>wheat</th>\n",
       "      <th>flour</th>\n",
       "      <th>sugar</th>\n",
       "      <th>chilli</th>\n",
       "      <th>red</th>\n",
       "      <th>...</th>\n",
       "      <th>tocopheryl</th>\n",
       "      <th>triethanolamine</th>\n",
       "      <th>cl</th>\n",
       "      <th>titanium</th>\n",
       "      <th>dioxide</th>\n",
       "      <th>root</th>\n",
       "      <th>stearate</th>\n",
       "      <th>orange</th>\n",
       "      <th>honey</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.240642</td>\n",
       "      <td>0.320856</td>\n",
       "      <td>0.481283</td>\n",
       "      <td>0.229947</td>\n",
       "      <td>0.251337</td>\n",
       "      <td>0.208556</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.224599</td>\n",
       "      <td>0.203209</td>\n",
       "      <td>0.171123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053476</td>\n",
       "      <td>0.053476</td>\n",
       "      <td>0.010695</td>\n",
       "      <td>0.048128</td>\n",
       "      <td>0.042781</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.037433</td>\n",
       "      <td>0.048128</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.524064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.428621</td>\n",
       "      <td>0.468059</td>\n",
       "      <td>0.500991</td>\n",
       "      <td>0.421928</td>\n",
       "      <td>0.434946</td>\n",
       "      <td>0.407367</td>\n",
       "      <td>0.425321</td>\n",
       "      <td>0.418438</td>\n",
       "      <td>0.403467</td>\n",
       "      <td>0.377627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225585</td>\n",
       "      <td>0.225585</td>\n",
       "      <td>0.103139</td>\n",
       "      <td>0.214612</td>\n",
       "      <td>0.202906</td>\n",
       "      <td>0.235926</td>\n",
       "      <td>0.190330</td>\n",
       "      <td>0.214612</td>\n",
       "      <td>0.235926</td>\n",
       "      <td>0.500761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           powder        salt         oil      edible   vegetable       wheat  \\\n",
       "count  187.000000  187.000000  187.000000  187.000000  187.000000  187.000000   \n",
       "mean     0.240642    0.320856    0.481283    0.229947    0.251337    0.208556   \n",
       "std      0.428621    0.468059    0.500991    0.421928    0.434946    0.407367   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    1.000000    1.000000    0.000000    0.500000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "            flour       sugar      chilli         red  ...  tocopheryl  \\\n",
       "count  187.000000  187.000000  187.000000  187.000000  ...  187.000000   \n",
       "mean     0.235294    0.224599    0.203209    0.171123  ...    0.053476   \n",
       "std      0.425321    0.418438    0.403467    0.377627  ...    0.225585   \n",
       "min      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
       "\n",
       "       triethanolamine          cl    titanium     dioxide        root  \\\n",
       "count       187.000000  187.000000  187.000000  187.000000  187.000000   \n",
       "mean          0.053476    0.010695    0.048128    0.042781    0.058824   \n",
       "std           0.225585    0.103139    0.214612    0.202906    0.235926   \n",
       "min           0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%           0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%           0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%           0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max           1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         stearate      orange       honey        TYPE  \n",
       "count  187.000000  187.000000  187.000000  187.000000  \n",
       "mean     0.037433    0.048128    0.058824    0.524064  \n",
       "std      0.190330    0.214612    0.235926    0.500761  \n",
       "min      0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000    1.000000  \n",
       "75%      0.000000    0.000000    0.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 114 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m = 187, n = 114\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "m, n = data.shape\n",
    "print(\"m = \" + str(m) + \", n = \" + str(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_train.shape = (140, 114)\n",
      "data_test.shape = (47, 114)\n"
     ]
    }
   ],
   "source": [
    "split_ratio = 0.75\n",
    "\n",
    "data_train = data[:int(m*split_ratio), :]\n",
    "data_test = data[int(m*split_ratio):, :]\n",
    "print(\"data_train.shape = \" + str(data_train.shape))\n",
    "\n",
    "print(\"data_test.shape = \" + str(data_test.shape))\n",
    "\n",
    "X_train = data_train[:, 0:n-1].T\n",
    "Y_train = data_train[:, n-1]\n",
    "X_test = data_test[:, 0:n-1].T\n",
    "Y_test = data_test[:, n-1]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using input and output layer with no hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "myn = nnetwork(113, 2, insertDefault=False ,learningRate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.9322099 ],\n",
       "       [0.57805523]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# myn.forward_prop(input_values=np.zeros(113))\n",
    "myn.forward_prop(input_values=X_train.T[30])\n",
    "# myn.forward_prop(input_values=X_train.T[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 113)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myn.output_layer.weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17576027,  0.12584528,  0.41712734, -0.41873679, -0.0239657 ,\n",
       "        -0.40661519, -0.1155656 , -0.47483832, -0.25291873, -0.10402701,\n",
       "        -0.1513087 ,  0.41713416,  0.35169556,  0.14810189, -0.41940541,\n",
       "        -0.39088118,  0.10618661,  0.27495659, -0.31353846,  0.05885413,\n",
       "         0.35885739,  0.35509614, -0.2144875 , -0.07963398,  0.11744041,\n",
       "        -0.0771674 ,  0.00309145,  0.43626009,  0.39287381,  0.28601095,\n",
       "        -0.17266099,  0.24595993,  0.19003903,  0.33790799, -0.07855008,\n",
       "        -0.27269725, -0.2956351 ,  0.36339629, -0.1456029 ,  0.03635656,\n",
       "        -0.32612996,  0.42041072,  0.40678625, -0.4390187 ,  0.25427817,\n",
       "        -0.32500696, -0.46669292, -0.18739201, -0.35526249, -0.42325394,\n",
       "         0.27060743, -0.28038394, -0.12636718, -0.06005911, -0.18440635,\n",
       "        -0.3789649 , -0.05909097,  0.33883287, -0.01843789,  0.00760644,\n",
       "         0.22843197,  0.31024526, -0.31006131, -0.42970735,  0.01385904,\n",
       "        -0.35876523,  0.19537079, -0.07758074, -0.22611663, -0.36671304,\n",
       "         0.11138901,  0.36936152, -0.22749178,  0.14117071,  0.21870466,\n",
       "        -0.39783933,  0.41333854,  0.01327294, -0.12066764, -0.0958969 ,\n",
       "        -0.38335083, -0.49568806, -0.333712  , -0.17782273, -0.2968281 ,\n",
       "         0.29322207, -0.43888563,  0.41348915, -0.38298359, -0.33569861,\n",
       "         0.47129472, -0.05693026,  0.39536073,  0.4919655 ,  0.25681906,\n",
       "         0.28478514, -0.26150965,  0.48304781, -0.09653104, -0.04207463,\n",
       "        -0.22184699,  0.41128367, -0.44492982, -0.40508909,  0.29584714,\n",
       "         0.17572423, -0.46535351,  0.38917126,  0.492649  , -0.44515879,\n",
       "        -0.12423709, -0.37089206,  0.4800548 ],\n",
       "       [-0.28348677,  0.07775152,  0.33615919,  0.23450294, -0.36509988,\n",
       "         0.04130411,  0.19557945, -0.05010054,  0.37979283,  0.34528481,\n",
       "         0.30915105,  0.05671028,  0.31866061, -0.15054958, -0.07867823,\n",
       "         0.24754544,  0.13314718,  0.13667521,  0.00512564, -0.32909722,\n",
       "         0.02831353,  0.06086116, -0.0348542 ,  0.17794859,  0.43603106,\n",
       "         0.23318994,  0.21301695,  0.4294523 , -0.06208601,  0.42836518,\n",
       "        -0.20600088,  0.10256833, -0.45125815, -0.11796005, -0.00916335,\n",
       "        -0.42880961, -0.22683912,  0.16819884, -0.26082377,  0.46532851,\n",
       "         0.27765051, -0.42760056,  0.47404608,  0.22327787,  0.01923702,\n",
       "        -0.41739672, -0.42453355, -0.07530671, -0.19816436, -0.00328576,\n",
       "         0.3223629 , -0.41692896,  0.48265117, -0.06740033,  0.26730749,\n",
       "        -0.46042236,  0.41750735, -0.30670438, -0.08274114,  0.30888077,\n",
       "         0.12971329, -0.03873327, -0.20182532,  0.45736517,  0.34284707,\n",
       "         0.38365154,  0.0872449 , -0.28787058, -0.12800061,  0.04994951,\n",
       "        -0.22223135,  0.17000624,  0.31281437,  0.41768954,  0.35501611,\n",
       "        -0.2523057 , -0.06963975, -0.12561653,  0.45324461, -0.35108834,\n",
       "         0.01768305,  0.21879272,  0.39834224,  0.32642616, -0.07671977,\n",
       "         0.27573286, -0.46102663, -0.07800334, -0.3297855 , -0.29430505,\n",
       "        -0.18803863,  0.34046554, -0.48239852, -0.48046154, -0.29786725,\n",
       "         0.03360203,  0.2176293 , -0.26779343, -0.27518837,  0.03545169,\n",
       "        -0.05814954,  0.26031733, -0.1173273 ,  0.49518896,  0.12518392,\n",
       "        -0.08859424,  0.17923098, -0.15334221, -0.17351636,  0.02892225,\n",
       "        -0.47773557, -0.16219243,  0.39125463]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myn.output_layer.weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(Y, maxExpected):\n",
    "    one_hot_Y = np.zeros((Y.size, maxExpected + 1))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    return one_hot_Y\n",
    "\n",
    "## find the index of most probable number guessed by network\n",
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, 0)\n",
    "\n",
    "## find ratio of correct predictions to all data\n",
    "def get_accuracy(predictions, Y):\n",
    "    # prin1(predictions, Y)\n",
    "    return np.sum(predictions == Y) / Y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17576027,  0.12584528,  0.41712734, -0.41873679, -0.0239657 ,\n",
       "        -0.40661519, -0.1155656 , -0.47483832, -0.25291873, -0.10402701,\n",
       "        -0.1513087 ,  0.41713416,  0.35169556,  0.14810189, -0.41940541,\n",
       "        -0.39088118,  0.10618661,  0.27495659, -0.31353846,  0.05885413,\n",
       "         0.35885739,  0.35509614, -0.2144875 , -0.07963398,  0.11744041,\n",
       "        -0.0771674 ,  0.00309145,  0.43626009,  0.39287381,  0.28601095,\n",
       "        -0.17266099,  0.24595993,  0.19003903,  0.33790799, -0.07855008,\n",
       "        -0.27269725, -0.2956351 ,  0.36339629, -0.1456029 ,  0.03635656,\n",
       "        -0.32612996,  0.42041072,  0.40678625, -0.4390187 ,  0.25427817,\n",
       "        -0.32500696, -0.46669292, -0.18739201, -0.35526249, -0.42325394,\n",
       "         0.27060743, -0.28038394, -0.12636718, -0.06005911, -0.18440635,\n",
       "        -0.3789649 , -0.05909097,  0.33883287, -0.01843789,  0.00760644,\n",
       "         0.22843197,  0.31024526, -0.31006131, -0.42970735,  0.01385904,\n",
       "        -0.35876523,  0.19537079, -0.07758074, -0.22611663, -0.36671304,\n",
       "         0.11138901,  0.36936152, -0.22749178,  0.14117071,  0.21870466,\n",
       "        -0.39783933,  0.41333854,  0.01327294, -0.12066764, -0.0958969 ,\n",
       "        -0.38335083, -0.49568806, -0.333712  , -0.17782273, -0.2968281 ,\n",
       "         0.29322207, -0.43888563,  0.41348915, -0.38298359, -0.33569861,\n",
       "         0.47129472, -0.05693026,  0.39536073,  0.4919655 ,  0.25681906,\n",
       "         0.28478514, -0.26150965,  0.48304781, -0.09653104, -0.04207463,\n",
       "        -0.22184699,  0.41128367, -0.44492982, -0.40508909,  0.29584714,\n",
       "         0.17572423, -0.46535351,  0.38917126,  0.492649  , -0.44515879,\n",
       "        -0.12423709, -0.37089206,  0.4800548 ],\n",
       "       [-0.28348677,  0.07775152,  0.33615919,  0.23450294, -0.36509988,\n",
       "         0.04130411,  0.19557945, -0.05010054,  0.37979283,  0.34528481,\n",
       "         0.30915105,  0.05671028,  0.31866061, -0.15054958, -0.07867823,\n",
       "         0.24754544,  0.13314718,  0.13667521,  0.00512564, -0.32909722,\n",
       "         0.02831353,  0.06086116, -0.0348542 ,  0.17794859,  0.43603106,\n",
       "         0.23318994,  0.21301695,  0.4294523 , -0.06208601,  0.42836518,\n",
       "        -0.20600088,  0.10256833, -0.45125815, -0.11796005, -0.00916335,\n",
       "        -0.42880961, -0.22683912,  0.16819884, -0.26082377,  0.46532851,\n",
       "         0.27765051, -0.42760056,  0.47404608,  0.22327787,  0.01923702,\n",
       "        -0.41739672, -0.42453355, -0.07530671, -0.19816436, -0.00328576,\n",
       "         0.3223629 , -0.41692896,  0.48265117, -0.06740033,  0.26730749,\n",
       "        -0.46042236,  0.41750735, -0.30670438, -0.08274114,  0.30888077,\n",
       "         0.12971329, -0.03873327, -0.20182532,  0.45736517,  0.34284707,\n",
       "         0.38365154,  0.0872449 , -0.28787058, -0.12800061,  0.04994951,\n",
       "        -0.22223135,  0.17000624,  0.31281437,  0.41768954,  0.35501611,\n",
       "        -0.2523057 , -0.06963975, -0.12561653,  0.45324461, -0.35108834,\n",
       "         0.01768305,  0.21879272,  0.39834224,  0.32642616, -0.07671977,\n",
       "         0.27573286, -0.46102663, -0.07800334, -0.3297855 , -0.29430505,\n",
       "        -0.18803863,  0.34046554, -0.48239852, -0.48046154, -0.29786725,\n",
       "         0.03360203,  0.2176293 , -0.26779343, -0.27518837,  0.03545169,\n",
       "        -0.05814954,  0.26031733, -0.1173273 ,  0.49518896,  0.12518392,\n",
       "        -0.08859424,  0.17923098, -0.15334221, -0.17351636,  0.02892225,\n",
       "        -0.47773557, -0.16219243,  0.39125463]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myn.output_layer.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
       "        0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "        1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "        1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0.],\n",
       "       [0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
       "        1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "        0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
       "        1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "        0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1.,\n",
       "        0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
       "        1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_oneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations = 0\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 50\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 100\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 150\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 200\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 250\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 300\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 350\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 400\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 450\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 500\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 550\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 600\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 650\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 700\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 750\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 800\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 850\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 900\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 950\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 1000\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 1050\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 1100\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 1150\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 1200\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 1250\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 1300\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 1350\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 1400\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 1450\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 1500\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 1550\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 1600\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 1650\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 1700\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 1750\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 1800\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 1850\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 1900\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 1950\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 2000\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 2050\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 2100\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 2150\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 2200\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 2250\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 2300\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 2350\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 2400\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 2450\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 2500\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 2550\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 2600\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 2650\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 2700\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 2750\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 2800\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 2850\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 2900\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 2950\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 3000\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 3050\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 3100\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 3150\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 3200\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 3250\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 3300\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 3350\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 3400\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 3450\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 3500\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 3550\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 3600\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 3650\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 3700\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 3750\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 3800\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 3850\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 3900\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 3950\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 4000\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 4050\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 4100\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 4150\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 4200\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 4250\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 4300\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 4350\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 4400\n",
      "Accuracy = 0.9714285714285714\n",
      "iterations = 4450\n",
      "Accuracy = 0.9714285714285714\n"
     ]
    }
   ],
   "source": [
    "# accuracySum = 0\n",
    "# runCount = 0\n",
    "\n",
    "telementary = 0\n",
    "\n",
    "lastWeights = myn.output_layer.weights\n",
    "\n",
    "dataLen = len(X_train)\n",
    "\n",
    "maxIt = 4500\n",
    "for it in range(maxIt):\n",
    "    Y_train_oneHot = one_hot(Y_train, maxExpected=1)\n",
    "    predictedRAW = myn.backward_prop(input_values=(X_train), trueOutput=Y_train_oneHot)\n",
    "\n",
    "    if(it % 50 == 0):\n",
    "        print(\"iterations =\", it)\n",
    "        predictions = get_predictions(predictedRAW[0][0])\n",
    "        print(\"Accuracy =\", get_accuracy(predictions, Y_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
